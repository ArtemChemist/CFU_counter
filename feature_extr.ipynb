{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 19:19:54.355279: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/art_usr/source_code/CFU_counter/512\n"
     ]
    }
   ],
   "source": [
    "# Resize images\n",
    "SIZE = 512\n",
    "p = os.path.abspath('.')\n",
    "output_dir = os.path.join(p, f'{SIZE}')\n",
    "#os.mkdir(output_dir)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob('./Thresholded/*'):\n",
    "\tfilename = file.split('/')[-1]\n",
    "\timg = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "\timg = cv2.resize(img, (SIZE,SIZE))\n",
    "\tnew_name = os.path.join(output_dir, filename)\n",
    "\tcv2.imwrite(new_name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = []\n",
    "labels = []\n",
    "\n",
    "for file in glob.glob(f'{output_dir}/*'):\n",
    "\tfilename = file.split('/')[-1]\n",
    "\tif filename[-5] == '0':\n",
    "\t\tlabels.append(0)\n",
    "\telse:\n",
    "\t\tlabels.append(1)\n",
    "\timage_names.append(filename)\n",
    "\n",
    "image_names = np.array(image_names)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 355 images with bacteria and 3997 without\n"
     ]
    }
   ],
   "source": [
    "#  Get two arrays with positive and negative images\n",
    "pos_im_files = [image_names[i] for i in range(image_names.shape[0]) if labels[i]]\n",
    "pos_im_files = np.array(pos_im_files)\n",
    "neg_im_files = [image_names[i] for i in range(image_names.shape[0]) if not labels[i]]\n",
    "neg_im_files = np.array(neg_im_files)\n",
    "num_pos = pos_im_files.shape[0]\n",
    "num_neg = neg_im_files.shape[0]\n",
    "print(f'There are {num_pos} images with bacteria and {num_neg} without')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(710,) (710,)\n"
     ]
    }
   ],
   "source": [
    "#  There are ~10x positive than negative.\n",
    "#  For initital training let's get all positive and equal number of negative\n",
    "#  For that:\n",
    "#  (1) Index of randomly selected negative images\n",
    "np.random.seed(0) # For reproducibility\n",
    "idx = np.random.choice(np.arange(neg_im_files.shape[0]), num_pos, replace = False)\n",
    "#  (2) Apply this index to the array of images\n",
    "neg_selected_files = neg_im_files[idx]\n",
    "#  (3) Make a full dataset, with X and y, not split into train.test yet\n",
    "X_files = np.concatenate((pos_im_files,neg_selected_files), axis =0)\n",
    "y = np.concatenate((np.ones(num_pos), np.zeros(neg_selected_files.shape[0])))\n",
    "print(X_files.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@213.379] global /opt/conda/conda-bld/opencv-suite_1664548337286/work/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('d256a8f3245839acee7f259ce920a2ec-70-0.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /opt/conda/conda-bld/opencv-suite_1664548337286/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m X_shuffled_files:\n\u001b[1;32m     14\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(file, cv2\u001b[39m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m---> 15\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_RGB2HSV)\n\u001b[1;32m     16\u001b[0m     images\u001b[39m.\u001b[39mappend(img)\n\u001b[1;32m     18\u001b[0m X_shuffled \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(images)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /opt/conda/conda-bld/opencv-suite_1664548337286/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Now shuffle the dataset and split it into 7/3 tran/test sets\n",
    "num_datapoints = X_files.shape[0]\n",
    "indices = np.arange(num_datapoints)\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "\n",
    "# Re-order training examples and corresponding labels using the randomly\n",
    "# shuffled indices.\n",
    "X_shuffled_files = X_files[shuffled_indices]\n",
    "y_shuffled = y[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read actual files:\n",
    "images = []\n",
    "for file_name in X_shuffled_files:\n",
    "    file = os.path.join(output_dir, filename)\n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    images.append(img)\n",
    "\n",
    "X_shuffled = np.array(images)\n",
    "\n",
    "# Split into test and train. Rely on random shuffling, can just take first 70% for train\n",
    "num_train = int(num_datapoints*0.7)\n",
    "\n",
    "x_train = X_shuffled[ :num_train, : , : , : ]\n",
    "y_train = y_shuffled[ :num_train]\n",
    "x_test = X_shuffled[num_train: , : , : , : ]\n",
    "y_test = y_shuffled[num_train: ]\n",
    "\n",
    "print(f'Set shape: train-> {x_train.shape}, test ->{x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set shape: train-> (496, 512, 512, 3), test ->(214, 512, 512, 3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize first 25 images to make sure it makes sense\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(12,12))\n",
    "\n",
    "row = 0\n",
    "label_name = \"Shirt predicted as coat\"\n",
    "axs[row,0].set_title(label_name)\n",
    "axs[row,0].axis('off')\n",
    "\n",
    "for i, j in [(i,j) for i in np.arange(5) for j in np.arange(5)]:\n",
    "    idx = 5*i+j\n",
    "    image = cv2.cvtColor(x_train[idx], cv2.COLOR_HSV2RGB)\n",
    "    axs[i,j].imshow(image)\n",
    "    axs[i,j].set_title(y_train[idx])\n",
    "    axs[i,j].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'sigmoid'\n",
    "\n",
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 3)))\n",
    "feature_extractor.add(batch_normalization.BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(batch_normalization.BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(batch_normalization.BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(batch_normalization.BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add layers for deep learning prediction\n",
    "x = feature_extractor.output  \n",
    "x = Dense(128, activation = activation, kernel_initializer = 'he_uniform')(x)\n",
    "prediction_layer = Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "# Make a new model combining both feature extractor and x\n",
    "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
    "cnn_model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "print(cnn_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = cnn_model.fit(x_train, y_train_one_hot, epochs=50, validation_data = (x_test, y_test_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save('./128')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_NN = cnn_model.predict(x_test)\n",
    "prediction_NN = np.argmax(prediction_NN, axis=-1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, prediction_NN)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let us use features from convolutional network for RF\n",
    "X_for_RF = feature_extractor.predict(x_train) #This is out X input to RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = feature_extractor.predict(x_test)\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_feature)\n",
    "\n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix - verify accuracy of each class\n",
    "cm = confusion_matrix(y_test, prediction_RF)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 25 mistakes\n",
    "error_idx = [i for i, rslt in enumerate(y_test) if (rslt + prediction_RF[i] == 1)]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=5, ncols=5, figsize=(12,12))\n",
    "\n",
    "for i, j in [(i,j) for i in np.arange(5) for j in np.arange(5)]:\n",
    "    idx = error_idx[5*i+j]\n",
    "    image = cv2.cvtColor(x_test[idx], cv2.COLOR_HSV2RGB)\n",
    "    axs[i,j].imshow(image)\n",
    "    axs[i,j].set_title(f'pred {int(prediction_RF[idx])}, real {int(y_test[idx])}')\n",
    "    axs[i,j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
